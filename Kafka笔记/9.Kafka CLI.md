#### 一.zookeeper启动命令

~~~bash
[root@dev ~]# zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties
~~~

Kafka的package里面自身已经有了zookeeper，所以不用另外下载zookeeper也可以。

zookeeper-server-start.sh是在kafka/bin/路径下面，启动的时候需要指定zookeeper的配置文件。

启动完成之后，最后会出现下面的日志

~~~bash
[2018-10-01 10:05:38,586] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
~~~

表示zookeeper启动成功，并且绑定的是本机的2181端口。

#### 二.kafka启动命令

~~~	bash
[root@dev ~]# kafka-server-start.sh /usr/local/kafka/config/server.properties
~~~

kafka在启动成功之后，最后会显示KafkaServer id

~~~bash
[2018-10-01 10:16:56,403] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
~~~

#### 三.kafka创建topic命令

~~~bash
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --topic first-topic --create --partitions 3 --replication-factor 2
Error while executing topic command : Replication factor: 2 larger than available brokers: 1.
[2018-10-01 10:32:49,327] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1.
 (kafka.admin.TopicCommand$)
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --topic first-topic --create --partitions 3 --replication-factor 1
Created topic "first-topic"
~~~

使用kafka-topic.sh命令创建topic，在创建topic的时候，需要指定一下选项

- --topic选项   用来指定topic名称
- --partitions选项   用来指定分区的个数
- --replication-factor选项 用来指定replication-factor，需要注意的是，replication-factor的个数不能大于当前broker的个数

~~~bash
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --list
first-topic
~~~

--list选项可以用来列出创建的所有的topic。

~~~bash
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --describe
Topic:first-topic	PartitionCount:3	ReplicationFactor:1	Configs:
	Topic: first-topic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: first-topic	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: first-topic	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
~~~

--describe选项用来列出关于该topic的详细信息，在上面的命令中，创建了3个分区。

信息中的Leader:0，这个0表示的是broker id为0的broker，因为在上面的创建过程中，只创建了一个broker，并且id为0，所以这里的三个分区的leader都是为0。

replicas表示的是replication(副本)，因为只有一个副本，从0开始，所以这里三个都为0。

#### 四.删除Topic命令

~~~bash
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --list
first-topic
second_topic
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --topic second_topic --delete
Topic second_topic is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --list
first-topic
[root@dev ~]# 
~~~

删除topic其实并不是真正的物理删除了这个topic，而是将要删除的topic的delete.topic.enable设置为了false。

####五.kafka-console-producer

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic first_topic --producer-property acks=all
>Today is a Good Day!!!
>I thik 
>^C[root@dev ~]# 
~~~

在通过kafka-console-producer命令给broker发送消息的时候，必须要指定两个参数

- --broker-list：这个参数的值是kafka broker服务器地址
- --topic：用来指定要发送消息到哪个topic上
- --producer-property：可选参数，用来指定发送消息时的参数

在执行kafka-console-producer命令的时候，如果指定的topic名称不存在，kafka将会创建这个topic，然后可以继续创建周的topic里写消息

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic new_topic
>Hello World
[2018-10-01 15:26:06,117] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 1 : {new_topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
>HHHHHH
>GGGGGG
>^C[root@dev ~]# 
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --list
first_topic
new_topic
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --topic new_topic --describe
Topic:new_topic	PartitionCount:1	ReplicationFactor:1	Configs:
	Topic: new_topic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
[root@dev ~]# 
~~~

但是这种通过kafka自动创建的topic，使用的都是默认的配置。

#### 六.kafka-console-consumer命令

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic

~~~

该命令必须的两个参数是：

- --bootstrap-server：用来指定broker服务器地址的
- --topic：用来指定topic名

执行上面的命令之后，光标一直在闪烁，并没有输出任何信息，这是因为这个命令只用于显示consumer开启之后，producer写入的信息，在consumer开启之前produer写入的信息并不会显示出来。

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic
Hello World
I am fine
~~~

在produer一侧不断的写入消息，会发现consumer这边也会开始显示producer写入的消息。

如果要想显示producer从一开始就写入的消息，就需要在命令上加入--from-beginning选项

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning
Today is a good day!!!
Today is a Good Day!!!
I thik 
Hello World
I am fine
~~~

#### 七.kafka consumer group

1、consumer是consomer group的一部分，在执行kafka-console-consumer.sh命令的时候，可以通过--group选项来设置consumer所属的group

producer：

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic first_topic
>Hello World
>I this you are very beautiful
>Ha haha
~~~

consumer：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic first_topic --group my_group
Hello World
I this you are very beautiful
Ha haha
~~~

consumer一侧通过选项—group指定了启动的consumer所属的group。对于producer一侧发送的消息，consumer可以正常接收。

2、当一个consumer group里面有两个consumer的时候，查看一下信息是怎么发送的

~~~bash
[root@dev ~]# kafka-topics.sh --zookeeper localhost:2181 --topic new_topic --describe
Topic:new_topic	PartitionCount:3	ReplicationFactor:1	Configs:
	Topic: new_topic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: new_topic	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: new_topic	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
~~~

new_topic这个主题里面有三个分区。

producer一侧发送的消息：

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic new_topic
>Hello World ①
>I love the world　②
>today is a good day　③
>he he he　④
>I ma learing kafka　⑤
>i want to eat something　⑥
>OK　⑦
>
~~~

第一个consumer接收到的消息：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group
Hello World ①
he he he　④
OK　⑦
~~~

第二个consumer接收到的消息：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group
I love the world　②
today is a good day　③
I ma learing kafka　⑤
i want to eat something　⑥
~~~

从上面的producer发送的消息以及两个consumer接受消息的对比，可以猜测出第一个consumer从一个new_topic主题的分区中接受消息，第二个consumer从两个consumer中接受消息。

3.下面开启三个my_group组的consumer看看是什么结果

producer发送的信息：

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic new_topic
>Hello World　①
>I Love the world　②
>hehehe　③
>AAAA　④
>BBBB　⑤
>CCCC　⑥
~~~

第一个consumer：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group
Hello World　①
AAAA　④
~~~

第二个consumer：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group
I Love the world　②
BBBB　⑤
~~~

第三个consumer：

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group
hehehe　③
CCCC　⑥
~~~

在consumer group中有三个consumer的时候，三个consumer依次从broker中接受producer发送的消息。

结合上面有两个consumer的情况，可以分析出，kafka会根据consumer的个数，自动调节consumer和partition的对应，以保证consumer在读取消息的时候可以保证平衡。

4.关于partition记录consumer读取信息偏移量的说明

①、producer发送消息

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic new_topic
>Hello
>world
>black
>red
>orange
~~~

如上图所示，producer一侧发送了以上的消息

开启一个consumer并从头开始读取producer的消息

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group --from-beginning
black
world
orange
Hello
red
^CProcessed a total of 5 messages
^C[root@dev ~]# ^C
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group --from-beginning
~~~

在第一次开启consumer的时候，指定了--from-beginning，将producer发送的消息全部都读了出来，然后停止该consumer，再以同样的方式开启consumer，会发现并没有跟之前的一样读取producer发送的所有消息。

②、producer继续发送消息

~~~bash
[root@dev ~]# kafka-console-producer.sh --broker-list localhost:9092 --topic new_topic
>Hello
>world
>black
>red
>orange
>monday
>tuesday
>
~~~

查看刚才启动的consumer接受消息的情况

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group --from-beginning
monday
tuesday
~~~

consumer接受了producer发送的monday和tuesday。

③、之后再次把consumer停止掉，然后以同样的--from-beginning的方式开启一个consumer

~~~bash
[root@dev ~]# kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic new_topic --group my_group --from-beginning
~~~

重新开启一个consumer，会发现consumer并没有从producer中读取任何的消息。

通过上面的这个实验可以看到partition关于记录consumer读取消息偏移量的问题。

partition中存储的消息，consumer读取之后，下次再次启动新的consumer，并不会读取之前已经被读取过的消息，这是因为partion会记录consumer读取信息偏移量的原因。